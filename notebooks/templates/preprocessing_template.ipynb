{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based aversive learning in humans is supported by preferential task state reactivation\n",
    "Wise\\*, Liu\\*, Chowdhury, & Dolan (2021)\n",
    "\n",
    "## MEG Preprocessing\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook performs preprocessing of localiser and task data. \n",
    "\n",
    "Preprocessing steps:\n",
    "\n",
    "1. Identification and loading of raw data\n",
    "2. Maxwell filtering\n",
    "3. Filtering\n",
    "4. ICA\n",
    "5. Epoching\n",
    "6. Downsampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.io import read_raw_fif\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import yaml\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "np.random.seed(100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS - OVERRRIDEN BY PAPERMILL EXECUTION\n",
    "data_dir = 'data/'  # Directory containing data\n",
    "session_id = '001'  # ID of the scanning session\n",
    "n_runs = 12  # Number of runs\n",
    "eye_tracking = True  # If True, eye-tracking measures will be used for exclusion of blink-related ICA components\n",
    "maxwell = True # If true, use maxwell filtering to clean data\n",
    "filter_low = 0.5 # Band pass lower freq\n",
    "filter_high = 0.5 # Band pass upper freq\n",
    "n_stim = 14  # Number of stimuli\n",
    "cores = 1  # Number of cores to use for parallel processing\n",
    "blink_components = None  # ICA components to remove\n",
    "downsample = True\n",
    "os.environ['OMP_NUM_THREADS'] = str(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_low == \"None\":\n",
    "    filter_low = None\n",
    "if filter_high == \"None\":\n",
    "    filter_high = None"
   ]
  },
  {
   "source": [
    "output_dir = 'data/derivatives/preprocessing/sub-{0}'.format(session_id)  # Where the output data should go"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Data is stored in [BIDS format](https://www.nature.com/articles/sdata2018110) - when I wrote this MNE didn't directly read from BIDS however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory for this subject\n",
    "data_dir = os.path.join(data_dir, 'sub-{0}'.format(session_id), 'ses-01', 'meg')\n",
    "\n",
    "# Find all files in the directory and make sure they're in the right order (i.e. ascending)\n",
    "data = os.listdir(data_dir)\n",
    "data = sorted([i for i in data if '.ds' in i and str(session_id) in i and not 'opt' in i])\n",
    "\n",
    "# Check we have the right number of runs\n",
    "assert len(data) == n_runs, \"Wrong number of data files, found {0}\".format(len(data))\n",
    "\n",
    "# See what has been found\n",
    "print(data)\n",
    "\n",
    "# Get all the data and read it in\n",
    "raws = []\n",
    "run_idx = range(0, n_runs)\n",
    "\n",
    "# Read in each data set\n",
    "for i in run_idx:\n",
    "    start_time = time.time()\n",
    "    raws.append(read_raw_fif(os.path.join(data_dir, data[i]), preload=True))\n",
    "    time_taken = time.time() - start_time\n",
    "    print(\"Time taken = {0}\".format(str(datetime.timedelta(seconds=time_taken))))\n",
    "\n",
    "# Concatenate the runs\n",
    "raw = mne.concatenate_raws(raws)\n",
    "\n",
    "# Get events\n",
    "print(\"FINDING EVENTS\")\n",
    "events = mne.find_events(raw, stim_channel='UPPT001', shortest_event=1)\n",
    "events[:, 0] += int((1 / 60 * 2) * raw.info['sfreq'])  # Adjust event times to compensate for projector lag (2 frames)\n",
    "\n",
    "del raws  # delete the list of raw data to conserve memory\n",
    "\n",
    "# We recorded at 1200hz, but this makes everything take FOREVER so we downsample to 600hz\n",
    "raw, events = raw.copy().resample(600, npad='auto', events=events)\n",
    "\n",
    "# Label eye-tracking channels as EOG\n",
    "raw.set_channel_types({'UADC001-2910': 'eog', 'UADC002-2901': 'eog', 'UADC003-2901': 'eog'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Maxwell filter\n",
    "This is partly because some MNE functions don't seem to work properly if CTF compensation is turned on, however Maxwell filtering also appears to do a better job than CTF compensation at removing noise from movement etc (https://martinos.org/mne/stable/auto_tutorials/plot_brainstorm_phantom_ctf.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if maxwell:\n",
    "    raw.apply_gradient_compensation(0)  # Remove CTF compensation\n",
    "    mf_kwargs = dict(origin=(0., 0., 0.), st_duration=10.)\n",
    "    raw = mne.preprocessing.maxwell_filter(raw, **mf_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n",
    "\n",
    "Highpass filter above 0.5hz, using windowed FIR filter with MNE default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FILTERING\")\n",
    "raw.filter(filter_low, filter_high, method='fir', fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA\n",
    "\n",
    "ICA is performed on the raw data and is set to find the number of components that explains 95% of the variance. \n",
    "\n",
    "We don't do much in terms of selecting noise-related components here - the data is generally pretty clean and doesn't seem to benefit much from extra denoising, so we simply automatically detect blink-related components based on eye-tracking channels.\n",
    "\n",
    "For some subjects eye tracking was poor due to equipment problems. If we're not able to identify a blink-related component automatically that may be due to an absent eye tracking channel, or just due to noisy eye tracking data - in this case the notebook uses provided components (these were identified manually in a previous run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ICA\n",
    "picks_meg = mne.pick_types(raw.info, meg=True, ref_meg=False)\n",
    "reject = dict(mag=5e-12, grad=4000e-13)\n",
    "ica = ICA(n_components=0.95, method='fastica',\n",
    "          random_state=100, max_iter=100).fit(raw, decim=50, picks=picks_meg, reject=reject)\n",
    "\n",
    "# Plot components\n",
    "ica.plot_components()\n",
    "\n",
    "# Save decomposition\n",
    "if not os.path.exists(os.path.join(output_dir, 'ICA')):\n",
    "    os.makedirs(os.path.join(output_dir, 'ICA'))\n",
    "ica.save(os.path.join(output_dir, 'ICA', 'sub-{0}_ses-01_task-AversiveLearningReplay_proc-ICA.fif.gz').format(session_id))\n",
    "\n",
    "# Find blink-related components\n",
    "if blink_components is None or blink_components == 'None':\n",
    "    blink_components, scores = ica.find_bads_eog(raw, threshold=1.5)\n",
    "    ica.plot_scores(scores, exclude=blink_components, labels='blink')\n",
    "    show_picks = np.abs(scores).argsort()[::-1][:5]\n",
    "    ica.plot_components(blink_components, colorbar=True)\n",
    "    \n",
    "# Find ECG componenhts\n",
    "ecg_epochs = create_ecg_epochs(raw, tmin=-.5, tmax=.5, picks=picks_meg)\n",
    "\n",
    "ecg_components, scores = ica.find_bads_ecg(ecg_epochs, method='ctps')\n",
    "ica.plot_scores(scores, exclude=ecg_components, labels='ecg')\n",
    "ecg_components = ecg_components[:3]\n",
    "\n",
    "print(\"APPLYING ICA\")\n",
    "\n",
    "# Only select a maximum of 2 components\n",
    "blink_components = blink_components[:2]\n",
    "\n",
    "ica.exclude = blink_components + ecg_components\n",
    "ica.apply(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create epochs\n",
    "\n",
    "Here we split the continuous data into epochs. Stimulus triggers are from 2 to the number of stimuli * 2 with a step of 2 (this is because sending odd numbers also triggers shocks in the actual task). Code 99 is used for null trials (only used in the localiser). We don't reject any trials because we want to decide on rejections later.\n",
    "\n",
    "We're only selecting the planning and rest periods from the task here as these are the periods we'll be looking at in later analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CATCH DUPLICATE EVENTS DUE TO PAUSES\n",
    "\n",
    "duplicate_idx = np.where(np.diff(events[:, 2]) == 0)[0]\n",
    "\n",
    "if np.any(events[duplicate_idx] == 60):\n",
    "    delete_idx = duplicate_idx[events[duplicate_idx, 2] == 60][0]\n",
    "    events = np.delete(events, delete_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behavioural data was mislabelled for one subject, this means the stimuli used for localiser and task aren't the same so we need to fix this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session_id == '001':\n",
    "    import re\n",
    "\n",
    "    beh_data_dir = os.path.join(data_dir, 'sub-{0}'.format(session_id), 'ses-01', 'beh')\n",
    "\n",
    "    # OLD - NEED TO MOVE BEHAVIOURAL FILES\n",
    "    localiser_stimuli_file = os.path.join('localiser/Data', [i for i in os.listdir('localiser/Data') if session_id in i and 'stimuli' in i][0])\n",
    "    task_stimuli_file = os.path.join('task/Data/behavioural/', [i for i in os.listdir('task/Data/behavioural/') if '001' in i and 'stimuli' in i][0])\n",
    "\n",
    "    # NEW \n",
    "    localiser_stimuli_file = os.path.join(beh_data_dir, 'sub-{0}_ses-01_task-AversiveLearningReplay_localiser-stim.csv'.format(session_id))\n",
    "    task_stimuli_file = os.path.join(beh_data_dir, 'sub-{0}_ses-01_task-AversiveLearningReplay_task-stim.csv'.format(session_id))\n",
    "    \n",
    "    def get_stimuli(log_file):\n",
    "        with open(log_file, 'r') as f:\n",
    "            stimuli = f.read().split(',')\n",
    "        stimuli = [re.search('[0-9]{2}', i).group() for i in stimuli]\n",
    "        return stimuli\n",
    "\n",
    "    def match_stimuli(localiser, task):\n",
    "        localiser_stimuli = get_stimuli(localiser)\n",
    "        task_stimuli = get_stimuli(task)\n",
    "        new_idx = [localiser_stimuli.index(i) for i in task_stimuli]\n",
    "        return new_idx\n",
    "\n",
    "    # This returns the correct indices for the task stimuli\n",
    "    correct_idx = match_stimuli(task_stimuli_file, localiser_stimuli_file)\n",
    "    \n",
    "    localiser_events = np.arange(2, n_stim * 2 + 2, 2)\n",
    "    \n",
    "    original_events = events.copy()\n",
    "    \n",
    "    for n, i in enumerate(localiser_events):\n",
    "        events[original_events[:, 2] == i, 2] = localiser_events[correct_idx][n]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EPOCHING\")\n",
    "\n",
    "# Get event names\n",
    "# Event numbers for the localiser are even numbers from 2 up to 2 * the number of stimuli\n",
    "localiser_event_names = dict([('stimulus_{0}'.format(i), i) for i in list(range(2, n_stim * 2 + 1, 2))])\n",
    "\n",
    "# We get task event numbers from the task config file\n",
    "with open('settings/replay_task_settings.yaml', 'rb') as f:\n",
    "    task_config = yaml.load(f)\n",
    "task_event_names = task_config['triggers']\n",
    "    \n",
    "# Occasionally planning triggers get coded as 62 instead of 60, so change any 62s to 60s. This might be just in cases with the incorrect trigger timing (M200-203)\n",
    "events[:, 2][events[:, 2] == 62] = 60\n",
    "events[:, 2][events[:, 2] == 98] = 99 # 98 for null events for one subject these got recorded as 98 rather than 99 for no apparent reason\n",
    "\n",
    "# Create the epoch objects\n",
    "localiser_epochs = mne.Epochs(raw, events[np.isin(events[:, 2], list(localiser_event_names.values()))], tmin=-0.5, tmax=0.8, preload=True, event_id=localiser_event_names,\n",
    "                              reject=None)\n",
    "planning_epochs = mne.Epochs(raw, events[np.isin(events[:, 2], list(task_event_names.values()))], \n",
    "                         tmin=0, tmax=np.max([task_config['MEG_durations']['start_duration'], task_config['MEG_durations']['rest_duration']]), \n",
    "                         preload=True, event_id={'planning': task_event_names['planning']}, reject=None)\n",
    "\n",
    "# Final state shown for 1.2 seconds, outcome for 2.8 seconds\n",
    "outcome_epochs = mne.Epochs(raw, events[np.isin(events[:, 2], list(task_event_names.values()))], \n",
    "                         tmin=-1.2, tmax=task_config['MEG_durations']['move_durations'][-1] - task_config['MEG_durations']['shock_symbol_delay'], \n",
    "                         preload=True, event_id={k: task_event_names[k] for k in ('shock_outcome', 'no_shock_outcome')}, reject=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOCALISER EVENTS\")\n",
    "\n",
    "for k, v in localiser_event_names.items():\n",
    "    print(\"Number of {0} events = {1}\".format(k, np.sum(events[:, 2] == v)))\n",
    "    \n",
    "print(\"TASK EVENTS\")\n",
    "\n",
    "for k, v in task_event_names.items():\n",
    "    print(\"Number of {0} events = {1}\".format(k, np.sum(events[:, 2] == v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for n, i in enumerate(np.unique(events[:, 2])):\n",
    "    data.append(go.Scatter(x=events[events[:, 2] == i][:, 0], y=[n] * len(events[events[:, 2] == i][:, 0]), mode = 'markers'))\n",
    "    \n",
    "\n",
    "layout = dict(title='Events', showlegend=False,\n",
    "              xaxis=dict(title='Samples'), yaxis=dict(title='Event ID', tickvals=np.arange(len(np.unique(events[:, 2]))), ticktext=[str(i) for i in np.unique(events[:, 2])]), \n",
    "              width=1500, height=600)\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='events')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the events look right\n",
    "\n",
    "First, we should have at least 700 localiser events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(localiser_epochs) > 700, 'Unexpected number of localiser trials, found {0}, expected 890'.format(len(localiser_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample\n",
    "\n",
    "Resampling to 100hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw  # Delete the raw data variable to save memory\n",
    "\n",
    "if downsample:\n",
    "    print(\"DOWNSAMPLING\")\n",
    "    print('Original sampling rate: {0} Hz'.format(localiser_epochs.info['sfreq']))\n",
    "    localiser_epochs = localiser_epochs.copy().resample(100, npad='auto')\n",
    "    planning_epochs = planning_epochs.copy().resample(100, npad='auto')\n",
    "    outcome_epochs = outcome_epochs.copy().resample(100, npad='auto')\n",
    "    print('Downsampled sampling rate: {0} Hz'.format(localiser_epochs.info['sfreq']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_epochs.save(os.path.join(output_dir, 'localiser', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id))\n",
    "planning_epochs.save(os.path.join(output_dir, 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz').format(session_id))\n",
    "outcome_epochs.save(os.path.join(output_dir, 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-outcome_proc_ICA-epo.fif.gz').format(session_id))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
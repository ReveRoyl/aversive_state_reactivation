{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay in Aversive Environments - Sequenceness analysis\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook uses the classifer trained on the localiser data to detect spontaneous state reactivation during the planning and rest phases of the task.\n",
    "\n",
    "Analysis steps:\n",
    "\n",
    "1. Loading task data and classifier\n",
    "2. Applying the classifer to the task data to generate time X state reactivation probabilities matrices\n",
    "3. Running the GLM-based sequenceness estimation procedure using a sliding window approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from state_prediction import *\n",
    "from sequenceness import *\n",
    "from utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS - OVERRRIDEN BY PAPERMILL EXECUTION\n",
    "session_id = '001'  # ID of the scanning session\n",
    "output_dir = 'data/derivatives'  # Where the output data should go\n",
    "window_width = 40  # Width of the sliding window used for sequenceness analysis\n",
    "classifier_window = [5, 6] # Window used for classification\n",
    "classifier_center_idx = 37  # The center index of the classification window, post stimulus onset\n",
    "max_lag = 20  # Maximum time-lag to look at sequenceness for\n",
    "correct_alpha = True  # Correct for alpha oscillations (only if using GLM)\n",
    "glm_constant = False  # Use constant (only if using GLM)\n",
    "method = 'cc'  # Method for assessing sequenceness, 'cc' for cross-correlation (e.g. Kurth-Nelson, Eldar), 'glm' for GLM (e.g. Liu)\n",
    "scale_data = False  # Scale state reactivation probabilities prior to sequenceness analysis\n",
    "n_stim = 14  # Number of stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State detection\n",
    "\n",
    "### Load the classifier\n",
    "\n",
    "First we load the classifier that we previously trained on the localiser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(os.path.join(output_dir, 'classifier', 'classifier_idx_{0}'.format(classifier_center_idx + 50), 'sub-{0}_classifier_idx_{1}.pkl').format(session_id, classifier_center_idx + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the task data\n",
    "\n",
    "We're interested in the planning and rest phases so we'll select these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing/task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz').format(session_id))\n",
    "outcome_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing/task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-task_outcome_proc_ICA-epo.fif.gz').format(session_id))\n",
    "\n",
    "# Get the data as a numpy array, excluding non-MEG channels\n",
    "picks_meg = mne.pick_types(planning_epochs.info, meg=True, ref_meg=False)\n",
    "planning_X = planning_epochs.get_data()[:, picks_meg, :] # MEG signals: n_epochs, n_channels, n_times\n",
    "outcome_X = outcome_epochs.get_data()[:, picks_meg, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(planning_X).any() == False, \"Nans present in planning data\"\n",
    "assert np.isnan(outcome_X).any() == False, \"Nans present in outcome data\"\n",
    "assert np.isinf(planning_X).any() == False, \"Infs present in planning data\"\n",
    "assert np.isinf(outcome_X).any() == False, \"Infs present in outcome data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State detection\n",
    "\n",
    "Here we iterate over trials, reshape the data for each trial into the format `[n_trials, n_sensors, n_timepoints]`, where the first dimension is 1 and the final dimension is the timepoint of interest plus additional adjacent timepoints used as extra features, and finally and use the `predict_proba` method of the fitted classifier to get predicted state reactivation probabilities for every timepoint within the trial.\n",
    "\n",
    "\n",
    "This involves a lot of for loops and could probably be made far more efficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_state_reactivation = predict_states(planning_X, clf, shifts=classifier_window, n_stim=n_stim)\n",
    "assert np.isnan(planning_state_reactivation).any() == False, \"Nans present in planning state reactivation array\"\n",
    "assert np.isinf(planning_state_reactivation).any() == False, \"Infs present in planning state reactivation array\"\n",
    "\n",
    "outcome_state_reactivation = predict_states(outcome_X, clf, shifts=classifier_window, n_stim=n_stim)\n",
    "assert np.isnan(outcome_state_reactivation).any() == False, \"Nans present in outcome state reactivation array\"\n",
    "assert np.isinf(outcome_state_reactivation).any() == False, \"Infs present in outcome state reactivation array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_planning_state_reactivation_idx_{1}.pkl'.format(session_id, classifier_center_idx)), planning_state_reactivation)\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir, 'state_reactivation_arrays', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'state_reactivation_arrays', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_outcome_state_reactivation_idx_{1}.pkl'.format(session_id, classifier_center_idx)), outcome_state_reactivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to StateReactivation class\n",
    "outcome_seq = StateReactivation(outcome_state_reactivation)\n",
    "planning_seq = StateReactivation(planning_state_reactivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequenceness analysis\n",
    "\n",
    "After determining the state reactivation probabilities for each trial, we can submit this data to the sequenceness analysis. We use a GLM approach here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transition matrix\n",
    "\n",
    "Here we load the transition matrix of the task, which is necessary for sequenceness analysis. We then subset this matrix to get the four arms of the task tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.loadtxt(r'task/Task_information/transition_matrix.txt')\n",
    "\n",
    "matrices = []\n",
    "\n",
    "# Select individual arms\n",
    "for start in [0, 1, 2, 3]:\n",
    "    if start in [0,1]:\n",
    "        m = select_path(transition_matrix, start, 12)\n",
    "    else:\n",
    "        m = select_path(transition_matrix, start, 13)\n",
    "    matrices.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sequenceness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_windowed_sequenceness = outcome_seq.get_windowed_sequenceness(max_lag, matrices, alpha=correct_alpha, \n",
    "                                                                      width=window_width, remove_first=False, constant=glm_constant, set_zero=False, scale=scale_data, method=method)\n",
    "planning_windowed_sequenceness = planning_seq.get_windowed_sequenceness(max_lag, matrices, alpha=correct_alpha, \n",
    "                                                                        width=window_width, remove_first=False, constant=glm_constant, set_zero=False, scale=scale_data, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the sequenceness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'sw_sequenceness', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'sw_sequenceness', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "joblib.dump(planning_windowed_sequenceness, os.path.join(output_dir, 'sw_sequenceness', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_planning_sequenceness_idx_{1}__{2}.pkl'.format(session_id, classifier_center_idx, method)))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir, 'sw_sequenceness', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'sw_sequenceness', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "joblib.dump(outcome_windowed_sequenceness, os.path.join(output_dir, 'sw_sequenceness', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_outcome_sequenceness_idx_{1}__{2}.pkl'.format(session_id, classifier_center_idx, method)))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
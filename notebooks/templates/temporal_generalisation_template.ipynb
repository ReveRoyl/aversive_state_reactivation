{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based aversive learning in humans is supported by preferential task state reactivation\n",
    "Wise*, Liu*, Chowdhury, & Dolam (2021)\n",
    "\n",
    "## Temporal generalisation\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook trains classifiers on the localiser data and uses them to predict choices on the task, giving us an index of reactivation.\n",
    "\n",
    "Temporal generalisation steps:\n",
    "\n",
    "1. Loading preprocessed data\n",
    "2. Training classifiers to predict distinguish pairs of stimuli (e.g. start stimuli for both paths) on the localiser\n",
    "3. Applying these classifiers to the task data to predict choice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "import os\n",
    "import mne\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore, UnsupervisedSpatialFilter, GeneralizingEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import halfcauchy\n",
    "from sklearn.metrics import make_scorer\n",
    "from sliding_window_classifiers import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_and_plot(clf, X, y, epochs):\n",
    "\n",
    "    scores = cross_val_multiscore(clf, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "    # Mean scores across cross-validation splits\n",
    "    mean_scores = np.mean(scores, axis=0)\n",
    "    best_idx = np.where(mean_scores == mean_scores.max())[0][0]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(dpi=100)\n",
    "    ax.axhline(1. / 2, color='#a8a8a8', linestyle='--', label='Chance')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Subset accuracy')\n",
    "    ax.axvline(.0, color='#515151', linestyle='-')\n",
    "    ax.set_title('Decoding accuracy')\n",
    "\n",
    "    corrected_times = epochs.times  \n",
    "\n",
    "    ax.plot(corrected_times[:len(mean_scores)], mean_scores, label='Score')\n",
    "    ax.axvline(corrected_times[best_idx], color='#76b9e8', linestyle='--')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "def time_accuracy(y, y_pred):\n",
    "    acc = y_pred == y[:, np.newaxis]\n",
    "    return (acc.sum(axis=0) / acc.shape[0]).mean()\n",
    "\n",
    "time_accuracy_scorer = make_scorer(time_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS - OVERRRIDEN BY PAPERMILL EXECUTION\n",
    "session_id = '001'  # ID of the scanning session\n",
    "n_stim = 14  # Number of stimuli\n",
    "n_iter_search = 100  # Number of iterations of the random search parameter optimisation procedure\n",
    "pca_n_components = 50  # Number of components used for PCA prior to classification\n",
    "classifier_regularisation = 'l1'  # Type of regularisation to use in the classifier\n",
    "param_optimisation_cv = 3  # Number of CV folds to use in evaluating the classifier\n",
    "cores = 1  # Number of cores to use for parallel processing\n",
    "os.environ['OMP_NUM_THREADS'] = str(cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_dir = 'data/derivatives/preprocessing/sub-{0}'.format(session_id)  # Where the output data should go\n",
    "output_dir = 'data/derivatives/temporal_generalisation/sub-{0}'.format(session_id)  # Where the output data should go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "This loads preprocessed data for the localiser and rest/outcome phases of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_epochs = mne.read_epochs(os.path.join(output_dir, 'localiser', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id)))\n",
    "planning_epochs = mne.read_epochs(os.path.join(output_dir, 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz').format(session_id))\n",
    "outcome_epochs = mne.read_epochs(os.path.join(output_dir, 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-outcome_proc_ICA-epo.fif.gz').format(session_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim epochs\n",
    "\n",
    "Here we remove any time before the start of the epoch as we don't need it for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_epochs.crop(0, None)\n",
    "outcome_epochs.crop(None, 2.8)\n",
    "planning_epochs.crop(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_epochs.pick_types(meg=True, ref_meg=False)\n",
    "outcome_epochs.pick_types(meg=True, ref_meg=False)\n",
    "planning_epochs.pick_types(meg=True, ref_meg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_dropped = np.zeros(len(outcome_epochs)).astype(bool)\n",
    "localiser_dropped = np.zeros(len(localiser_epochs)).astype(bool)\n",
    "planning_dropped = np.zeros(len(planning_epochs)).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up classifiers and train on localiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classifier\n",
    "\n",
    "First we create classifier instances that will be used for all further analyses. We use a regularised logistic regression, with the data subject to dimensionality reduction through PCA.\n",
    "\n",
    "We will train and test this classifier on the localiser data first, optimising the regularisation parameter (`C`) to find the best decoding accuracy. We will then use this value of `C` in our temporal generalisation analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegression(C=0.1, penalty=classifier_regularisation, class_weight=\"balanced\", solver='liblinear'))\n",
    "pca = UnsupervisedSpatialFilter(PCA(pca_n_components), average=False)\n",
    "pca.fit(localiser_epochs.get_data())\n",
    "sliding = SlidingEstimator(clf, scoring='accuracy', n_jobs=1, verbose=False)\n",
    "param_dist = {\"base_estimator__logisticregression__C\": halfcauchy(scale=5)}\n",
    "random_search = RandomizedSearchCV(sliding, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=param_optimisation_cv, n_jobs=1, scoring=time_accuracy_scorer, verbose=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning paths - Start states\n",
    "\n",
    "Here we train a classifier to distinguish the two images representing the first image in each learning path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_X_data = pca.transform(localiser_epochs[['stimulus_2', 'stimulus_8']].get_data())\n",
    "random_search.fit(X=localiser_X_data,  y=localiser_epochs[['stimulus_2', 'stimulus_8']].events[:, 2] > 2)\n",
    "best_C_learning = random_search.best_params_['base_estimator__logisticregression__C']\n",
    "scores = score_and_plot(random_search.best_estimator_, localiser_X_data, localiser_epochs[['stimulus_2', 'stimulus_8']].events[:, 2] > 2, localiser_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisation paths - Start states\n",
    "\n",
    "This trains a classifier to distinguish between the images representing the start states in the two generalisation paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_X_data = pca.transform(localiser_epochs[['stimulus_4', 'stimulus_6']].get_data())\n",
    "random_search.fit(X=localiser_X_data,  y=localiser_epochs[['stimulus_4', 'stimulus_6']].events[:, 2] > 4)\n",
    "best_C_generalisation = random_search.best_params_['base_estimator__logisticregression__C']\n",
    "scores = score_and_plot(random_search.best_estimator_, localiser_X_data, localiser_epochs[['stimulus_4', 'stimulus_6']].events[:, 2] > 4, localiser_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End states\n",
    "\n",
    "This trains a classifier to distinguish between the images representing the two end states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localiser_X_data = pca.transform(localiser_epochs[['stimulus_26', 'stimulus_28']].get_data())\n",
    "random_search.fit(X=localiser_X_data,  y=localiser_epochs[['stimulus_26', 'stimulus_28']].events[:, 2] > 26)\n",
    "best_C_end = random_search.best_params_['base_estimator__logisticregression__C']\n",
    "scores = score_and_plot(random_search.best_estimator_, localiser_X_data, localiser_epochs[['stimulus_26', 'stimulus_28']].events[:, 2] > 26, localiser_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up generalising estimator for learning and generalisation start states, and end states\n",
    "\n",
    "Here we set up classifiers that are used for the temporal generalisation analysis, using the optimal values for `C` determined in the prior analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_learning = make_pipeline(StandardScaler(), LogisticRegression(C=best_C_learning, penalty=classifier_regularisation, class_weight=\"balanced\", solver='liblinear'))\n",
    "clf_generalisation = make_pipeline(StandardScaler(), LogisticRegression(C=best_C_generalisation, penalty=classifier_regularisation, class_weight=\"balanced\", solver='liblinear'))\n",
    "clf_end = make_pipeline(StandardScaler(), LogisticRegression(C=best_C_end, penalty=classifier_regularisation, class_weight=\"balanced\", solver='liblinear'))\n",
    "\n",
    "time_gen_learning = GeneralizingEstimator(clf_learning, scoring='accuracy', n_jobs=1, verbose=False)\n",
    "time_gen_generalisation = GeneralizingEstimator(clf_generalisation, scoring='accuracy', n_jobs=1, verbose=False)\n",
    "time_gen_end = GeneralizingEstimator(clf_end, scoring='accuracy', n_jobs=1, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we then fit these to the localiser data. This involves training a classifier on each timepoint of the localiser trials, which we can then apply to each timepoint in the task trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_gen_learning.fit(X=pca.transform(localiser_epochs[['stimulus_2', 'stimulus_8']].get_data()), y=localiser_epochs[['stimulus_2', 'stimulus_8']].events[:, 2] > 2)\n",
    "time_gen_generalisation.fit(X=pca.transform(localiser_epochs[['stimulus_4', 'stimulus_6']].get_data()), y=localiser_epochs[['stimulus_4', 'stimulus_6']].events[:, 2] > 4)\n",
    "time_gen_end.fit(X=pca.transform(localiser_epochs[['stimulus_26', 'stimulus_28']].get_data()), y=localiser_epochs[['stimulus_26', 'stimulus_28']].events[:, 2] > 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict behaviour on the task\n",
    "\n",
    "Next we use our classifiers to predict which paths subjects chose on each trial. We assume that if we can classify behaviour using a classifer trained only on the perceptual qualities used to define each state, this provides evidence that those perceptual qualities are being reactivated in a way that is associated with behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_data_dir = os.path.join(data_dir, 'sub-{0}'.format(session_id), 'ses-01', 'beh')\n",
    "\n",
    "behaviour = pd.read_csv(os.path.join(beh_data_dir, 'sub-{0}_ses-01_task-AversiveLearningReplay_responses.csv'.format(behaviour_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA to task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_X_data = pca.transform(outcome_epochs.get_data())\n",
    "planning_X_data = pca.transform(planning_epochs.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifers to task data and score\n",
    "\n",
    "This loops through each time point in the planning and rest periods of the task, applying the localiser trained on every time point at each. We look at learning and generalisation trials both together and separately to determine effects that are present across all and those that are specific to one trial type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome - all trials\n",
    "all_trials_outcome_learning_scores = time_gen_learning.score(X=outcome_X_data, y=behaviour[behaviour.trial_type == 0].loc[~outcome_dropped.astype(bool), 'State_4_shown'] > 12)\n",
    "all_trials_outcome_generalisation_scores = time_gen_generalisation.score(X=outcome_X_data, y=behaviour[behaviour.trial_type == 0].loc[~outcome_dropped.astype(bool), 'State_4_shown'] > 12)\n",
    "all_trials_outcome_end_scores = time_gen_end.score(X=outcome_X_data, y=behaviour[behaviour.trial_type == 0].loc[~outcome_dropped.astype(bool), 'State_4_shown'] > 12)\n",
    "\n",
    "# Planning - all trials\n",
    "all_trials_planning_learning_scores = time_gen_learning.score(X=planning_X_data, y=behaviour.loc[~planning_dropped.astype(bool), 'State_4_shown'] > 12)\n",
    "all_trials_planning_generalisation_scores = time_gen_generalisation.score(X=planning_X_data, y=behaviour.loc[~planning_dropped.astype(bool), 'State_4_shown'] > 12)\n",
    "all_trials_planning_end_scores = time_gen_end.score(X=planning_X_data, y=behaviour.loc[~planning_dropped.astype(bool), 'State_4_shown'] > 12)\n",
    "\n",
    "# Planning - learning trials\n",
    "planning_behaviour = behaviour[~planning_dropped]\n",
    "learning_trials_planning_learning_scores = time_gen_learning.score(X=planning_X_data[planning_behaviour.trial_type == 0], \n",
    "                                                                   y=planning_behaviour[planning_behaviour.trial_type == 0]['State_4_shown'] > 12)\n",
    "learning_trials_planning_generalisation_scores = time_gen_generalisation.score(X=planning_X_data[planning_behaviour.trial_type == 0], \n",
    "                                                                               y=planning_behaviour[planning_behaviour.trial_type == 0]['State_4_shown'] > 12)\n",
    "learning_trials_planning_end_scores = time_gen_end.score(X=planning_X_data[planning_behaviour.trial_type == 0], \n",
    "                                                         y=planning_behaviour[planning_behaviour.trial_type == 0]['State_4_shown'] > 12)\n",
    "\n",
    "# Planning - generalisation trials\n",
    "generalisation_trials_planning_learning_scores = time_gen_learning.score(X=planning_X_data[planning_behaviour.trial_type == 1], \n",
    "                                                                         y=planning_behaviour[planning_behaviour.trial_type == 1]['State_4_shown'] > 12)\n",
    "generalisation_trials_planning_generalisation_scores = time_gen_generalisation.score(X=planning_X_data[planning_behaviour.trial_type == 1], \n",
    "                                                                                     y=planning_behaviour[planning_behaviour.trial_type == 1]['State_4_shown'] > 12)\n",
    "generalisation_trials_planning_end_scores = time_gen_end.score(X=planning_X_data[planning_behaviour.trial_type == 1], \n",
    "                                                               y=planning_behaviour[planning_behaviour.trial_type == 1]['State_4_shown'] > 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(15, 8), dpi=100, gridspec_kw={'width_ratios': [0.5, 1]})\n",
    "\n",
    "labels = ['learning', 'generalisation', 'end']\n",
    "\n",
    "for n, i in enumerate([all_trials_outcome_learning_scores, all_trials_outcome_generalisation_scores, all_trials_outcome_end_scores]):\n",
    "    \n",
    "    im = ax[n, 0].matshow(i, vmin=0, vmax=1., cmap='RdBu_r', origin='lower')\n",
    "    ax[n, 0].axhline(0., color='k')\n",
    "    ax[n, 0].axvline(0., color='k')\n",
    "    ax[n, 0].xaxis.set_ticks_position('bottom')\n",
    "    ax[n, 0].set_xticks(np.arange(0, len(outcome_epochs.times), 50))\n",
    "    ax[n, 0].set_xticklabels(outcome_epochs.times[::50])\n",
    "    ax[n, 0].set_xlabel('Testing Time (s)')\n",
    "    ax[n, 0].set_ylabel('Training\\nTime (s)')\n",
    "    ax[n, 0].set_title('Outcome ({0})'.format(labels[n]))\n",
    "\n",
    "for n, i in enumerate([all_trials_planning_learning_scores, all_trials_planning_generalisation_scores, all_trials_planning_end_scores]):\n",
    "    \n",
    "    im = ax[n, 1].matshow(i, vmin=0, vmax=1., cmap='RdBu_r', origin='lower')\n",
    "    ax[n, 1].axhline(0., color='k')\n",
    "    ax[n, 1].axvline(0., color='k')\n",
    "    ax[n, 1].xaxis.set_ticks_position('bottom')\n",
    "    ax[n, 1].set_xticks(np.arange(0, len(planning_epochs.times), 50))\n",
    "    ax[n, 1].set_xticklabels(planning_epochs.times[::50])\n",
    "    ax[n, 1].set_xlabel('Testing Time (s)')\n",
    "    ax[n, 1].set_ylabel('Trainin\\nTime (s)')\n",
    "    ax[n, 1].set_title('Planning ({0})'.format(labels[n]))\n",
    "plt.subplots_adjust(bottom=0.3, right=0.8, top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation/outcome/all_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation/outcome/all_trials'))\n",
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation/planning/all_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation/planning/all_trials'))\n",
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation/planning/learning_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation/planning/learning_trials'))\n",
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation/planning/generalisation_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation/planning/generalisation_trials'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(output_dir, 'temporal_generalisation/outcome/all_trials', 'sub-{0}_learning_stimulus_outcome').format(session_id), all_trials_outcome_learning_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/outcome/all_trials', 'sub-{0}_generalisation_stimulus_outcome').format(session_id), all_trials_outcome_generalisation_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/outcome/all_trials', 'sub-{0}_end_stimulus_outcome').format(session_id), all_trials_outcome_end_scores)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/all_trials', 'sub-{0}_learning_stimulus_planning').format(session_id), all_trials_planning_learning_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/all_trials', 'sub-{0}_generalisation_stimulus_planning').format(session_id), all_trials_planning_generalisation_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/all_trials', 'sub-{0}_end_stimulus_planning').format(session_id), all_trials_planning_end_scores)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/learning_trials', 'sub-{0}_learning_stimulus_planning').format(session_id), learning_trials_planning_learning_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/learning_trials', 'sub-{0}_generalisation_stimulus_planning').format(session_id), learning_trials_planning_generalisation_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/learning_trials', 'sub-{0}_end_stimulus_planning').format(session_id), learning_trials_planning_end_scores)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/generalisation_trials', 'sub-{0}_learning_stimulus_planning').format(session_id), generalisation_trials_planning_learning_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/generalisation_trials', 'sub-{0}_generalisation_stimulus_planning').format(session_id), generalisation_trials_planning_generalisation_scores)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation/planning/generalisation_trials', 'sub-{0}_end_stimulus_planning').format(session_id), generalisation_trials_planning_end_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifers to task data to get probabilistic predictions\n",
    "\n",
    "This loops through each time point in the planning and rest periods of the task, applying the localiser trained on every time point at each. We look at learning and generalisation trials both together and separately to determine effects that are present across all and those that are specific to one trial type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome - all trials\n",
    "all_trials_outcome_learning_pred = time_gen_learning.predict_proba(X=outcome_X_data)\n",
    "all_trials_outcome_generalisation_pred = time_gen_generalisation.predict_proba(X=outcome_X_data)\n",
    "all_trials_outcome_end_pred = time_gen_end.predict_proba(X=outcome_X_data)\n",
    "\n",
    "# # Planning - all trials\n",
    "all_trials_planning_learning_pred = time_gen_learning.predict_proba(X=planning_X_data)\n",
    "all_trials_planning_generalisation_pred = time_gen_generalisation.predict_proba(X=planning_X_data)\n",
    "all_trials_planning_end_pred = time_gen_end.predict_proba(X=planning_X_data)\n",
    "\n",
    "# # # Planning - learning trials\n",
    "planning_behaviour = behaviour[~planning_dropped]\n",
    "learning_trials_planning_learning_pred = time_gen_learning.predict_proba(X=planning_X_data[planning_behaviour.trial_type == 0])\n",
    "learning_trials_planning_generalisation_pred = time_gen_generalisation.predict_proba(X=planning_X_data[planning_behaviour.trial_type == 0])\n",
    "learning_trials_planning_end_pred = time_gen_end.predict_proba(X=planning_X_data[planning_behaviour.trial_type == 0])\n",
    "\n",
    "# # # Planning - generalisation trials\n",
    "generalisation_trials_planning_learning_pred = time_gen_learning.predict_proba(X=planning_X_data[planning_behaviour.trial_type == 1])\n",
    "generalisation_trials_planning_generalisation_pred = time_gen_generalisation.predict_proba(X=planning_X_data[planning_behaviour.trial_type == 1])\n",
    "generalisation_trials_planning_end_pred = time_gen_end.predict_proba(X=planning_X_data[planning_behaviour.trial_type == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(15, 8), dpi=100, gridspec_kw={'width_ratios': [0.5, 1]})\n",
    "\n",
    "labels = ['learning', 'generalisation', 'end']\n",
    "\n",
    "for n, i in enumerate([all_trials_outcome_learning_pred, all_trials_outcome_generalisation_pred, all_trials_outcome_end_pred]):\n",
    "    \n",
    "    im = ax[n, 0].matshow(i.mean(axis=0)[:, :, 0], vmin=0, vmax=1., cmap='RdBu_r', origin='lower')\n",
    "    ax[n, 0].axhline(0., color='k')\n",
    "    ax[n, 0].axvline(0., color='k')\n",
    "    ax[n, 0].xaxis.set_ticks_position('bottom')\n",
    "    ax[n, 0].set_xticks(np.arange(0, len(outcome_epochs.times), 50))\n",
    "    ax[n, 0].set_xticklabels(outcome_epochs.times[::50])\n",
    "    ax[n, 0].set_xlabel('Testing Time (s)')\n",
    "    ax[n, 0].set_ylabel('Training\\nTime (s)')\n",
    "    ax[n, 0].set_title('Outcome ({0})'.format(labels[n]))\n",
    "\n",
    "for n, i in enumerate([all_trials_planning_learning_pred, all_trials_planning_generalisation_pred, all_trials_planning_end_pred]):\n",
    "    \n",
    "    im = ax[n, 1].matshow(i.mean(axis=0)[:, :, 0], vmin=0, vmax=1., cmap='RdBu_r', origin='lower')\n",
    "    ax[n, 1].axhline(0., color='k')\n",
    "    ax[n, 1].axvline(0., color='k')\n",
    "    ax[n, 1].xaxis.set_ticks_position('bottom')\n",
    "    ax[n, 1].set_xticks(np.arange(0, len(planning_epochs.times), 50))\n",
    "    ax[n, 1].set_xticklabels(planning_epochs.times[::50])\n",
    "    ax[n, 1].set_xlabel('Testing Time (s)')\n",
    "    ax[n, 1].set_ylabel('Trainin\\nTime (s)')\n",
    "    ax[n, 1].set_title('Planning ({0})'.format(labels[n]))\n",
    "plt.subplots_adjust(bottom=0.3, right=0.8, top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation_predicted/outcome/all_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation_predicted/outcome/all_trials'))\n",
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/all_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/all_trials'))\n",
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/learning_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/learning_trials'))\n",
    "if not os.path.exists(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/generalisation_trials')):\n",
    "    os.makedirs(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/generalisation_trials'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/outcome/all_trials', 'sub-{0}_learning_stimulus_outcome').format(session_id), all_trials_outcome_learning_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/outcome/all_trials', 'sub-{0}_generalisation_stimulus_outcome').format(session_id), all_trials_outcome_generalisation_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/outcome/all_trials', 'sub-{0}_end_stimulus_outcome').format(session_id), all_trials_outcome_end_pred)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/all_trials', 'sub-{0}_learning_stimulus_planning').format(session_id), all_trials_planning_learning_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/all_trials', 'sub-{0}_generalisation_stimulus_planning').format(session_id), all_trials_planning_generalisation_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/all_trials', 'sub-{0}_end_stimulus_planning').format(session_id), all_trials_planning_end_pred)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/learning_trials', 'sub-{0}_learning_stimulus_planning').format(session_id), learning_trials_planning_learning_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/learning_trials', 'sub-{0}_generalisation_stimulus_planning').format(session_id), learning_trials_planning_generalisation_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/learning_trials', 'sub-{0}_end_stimulus_planning').format(session_id), learning_trials_planning_end_pred)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/generalisation_trials', 'sub-{0}_learning_stimulus_planning').format(session_id), generalisation_trials_planning_learning_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/generalisation_trials', 'sub-{0}_generalisation_stimulus_planning').format(session_id), generalisation_trials_planning_generalisation_pred)\n",
    "np.save(os.path.join(output_dir, 'temporal_generalisation_predicted/planning/generalisation_trials', 'sub-{0}_end_stimulus_planning').format(session_id), generalisation_trials_planning_end_pred)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}